# Kubelet Part 2: CNI

- https://medium.com/@ElieXU/run-kubelet-1-24-standalone-using-docker-engine-part-2-ae3f9a20882a

## A Note On Kubelet Part 1

- I have several docs following the part 1 of the series
- I ended up using containerd instead of docker and docker-cri
- I am still using Vagrant, qemu, MacOS

## Summary So Far

```bash
# what boxes are running?
vagrant global-status
# log into the box
vagrant ssh

# remember some stuff about the box
# on ubuntu
dpkg --print-architecture # arm64
# on RPM based systems
rpm --eval '%{_arch}'
# then also
uname -a
# release stuff
lsb_release -a

# go!
which go
go version

# what did we build again?
sudo apt install tree
tree kubernetes/_output/bin/

# what is all running? ugh, too much
systemctl list-units

# containerd still happy? (.service automatically appended)
systemctl status containerd

# our kubelet config still ok?
# kubeletConfigFile.yaml?
ls configs/

# any pod.yamls exist that the kubelet is monitoring?
# NOTE: the kubelet is only watching this if it is
# still running in another window, unless I have it
# setup to run all the time.
ls kubelet-static-pod/

# soft link the built kubelet to our $HOME dir
ln -s ./kubernetes/_output/bin/kubelet ./kubelet

# start the local kubelet
sudo ./kubelet --config ./configs/kubeletConfigFile.yaml

# optionally run it as a daemon via systemd
# however, there is more complexity to this
# and I didn't finish setting it up.
sudo systemctl status kubelet.service

# containerd is running as a daemon already via
# systemd / sytemctl.  Review prev notes for this.
```

See [Systemd Kubelet Unit](./1.systemd.kubelet.unit.md) for
some notes on starting to setup the kubelet with systemd


## Onward to CNI

- [Network Plugins](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)

CI is a framework for configuring network resources.
The CNI plugin is for Kubernetes Cluster network configuration.

Prior to Kubernetes 1.24
- `kubelet` coudl manage CNI plugins.  Now it cannot.
- `kubelet` had `--cni-bin-dir` and `--network-plugin` command
  line options.  now it does not.
- The CNI plugins were removed along with the docker-shim.

Reviewing a `Container Runtime` in the `networking context`.
- A Container Runtime, in the networking context, is a daemon
  on a node configured to provide CRI Services for `kubelet`.
- In particular, the Container Runtie must be configured to load
  the CNI plugins required to implement the Kubernetes
  network model.

Several `Container Runtimes` will provide documentation for
configuring CNI plugins:

- [containerd](https://github.com/containerd/containerd/blob/main/script/setup/install-cni)
  - This is a `bash script`
    - [RAW for wget](https://raw.githubusercontent.com/containerd/containerd/main/script/setup/install-cni)
- [CRI-O](https://github.com/cri-o/cri-o/blob/main/contrib/cni/README.md)

It is also possible to just `wget` the CNI plugins release:

```bash
# get the release
wget https://github.com/containernetworking/plugins/releases/download/v1.5.1/cni-plugins-linux-arm64-v1.5.1.tgz

# in part 1, we instead cloned and built
git clone https://github.com/containernetworking/plugins
# name it something reasonable
mv plugins containernetworking_plugins
cd containernetworking_plugins/
# git checkout v1.1.1 # might be fine to use latest now
./build_linux.sh # this seems to do quite a bit!
sudo mkdir -p /opt/cni/bin
sudo cp bin/* /opt/cni/bin
```

## Network Plugin Requirements

In addition to the CNI plugin for the Kubernetes network model,
Kubernetes requires a `loopback interface`.
- the plugins do come with a `loopback` binary

The CNI network plugin supports `hostPort`.
There is also a `portMap` plugin.

## Containerd and Network Plugins

The article utilizes `docker` and `cri-dockerd`, but I opted
to go with `containerd` due to issues keeping docker running in
my Vagrant box.  So I deviate here.

```bash
● containerd.service - containerd container runtime
     Loaded: loaded (/lib/systemd/system/containerd.service; enabled; vendor preset: enabled)
     Active: active (running) since Thu 2024-06-27 02:00:33 UTC; 24h ago
       Docs: https://containerd.io
   Main PID: 40682 (containerd)
      Tasks: 36
     Memory: 317.7M
        CPU: 2min 46.008s
     CGroup: /system.slice/containerd.service
             ├─ 40682 /usr/local/bin/containerd
             ├─ 71614 /usr/local/bin/containerd-shim-runc-v2 -namespace k8s.io -id 38fc0d4b9d1a34f1b78249c043322e568364868d6a27ebd30882d3b90915a4c1 -address /run/containerd/containerd.sock
             └─112841 /usr/local/bin/containerd-shim-runc-v2 -namespace k8s.io -id 74106d346cbe18839ff953e8f7079076c901e68c30719d2fe6af70dd749fedce -address /run/containerd/containerd.sock

# some logs...
msg="StartContainer for \"307d52790e3f36b80bd80263f5c3e6653596a7d9ea96fba4931f2c77b046793d\""
# un oh? no CNI?
msg="No cni config template is specified, wait for other system components to drop the config."
```

But I believe this is because I deleted the `/opt/cni` directory before restarting
`containerd`.  Once I git cloned & rebuilt the CNI plugins, and put them back in
`/opt/cni`, then I restarted containerd:

```bash
# once we put back CNI in `/opt/cni` we restart
sudo systemct restart containerd.service
# and check on things.  All good? looks good now.
systemctl status containerd.service
containerd.service - containerd container runtime
     Loaded: loaded (/lib/systemd/system/containerd.service; enabled; vendor preset: enabled)
     Active: active (running) since Fri 2024-06-28 21:28:10 UTC; 4s ago
       Docs: https://containerd.io
    Process: 115552 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS)
   Main PID: 115553 (containerd)
      Tasks: 35
     Memory: 325.5M
        CPU: 111ms
     CGroup: /system.slice/containerd.service
             ├─ 71614 /usr/local/bin/containerd-shim-runc-v2 -namespace k8s.io -id 38fc0d4b9d1a34f1b78249c043322e568364868d6a27ebd30882d3b90915a4c1 -address /run/containerd/con>
             ├─112841 /usr/local/bin/containerd-shim-runc-v2 -namespace k8s.io -id 74106d346cbe18839ff953e8f7079076c901e68c30719d2fe6af70dd749fedce -address /run/containerd/con>
             └─115553 /usr/local/bin/containerd

Jun 28 21:28:10 qemu-ubuntu-containerd containerd[115553]: time="2024-06-28T21:28:10.824056465Z" level=info msg=serving... address=/run/containerd/containerd.sock.ttrpc
# seems like CNI is good again
# qemu-ubuntu-containerd is our Vagrant box name
Jun 28 21:28:10 qemu-ubuntu-containerd containerd[115553]: time="2024-06-28T21:28:10.836717162Z" level=info msg="Start cni network conf syncer for default"
Jun 28 21:28:10 qemu-ubuntu-containerd containerd[115553]: time="2024-06-28T21:28:10.836745663Z" level=info msg="starting plugins..."
Jun 28 21:28:10 qemu-ubuntu-containerd containerd[115553]: time="2024-06-28T21:28:10.836851253Z" level=info msg="containerd successfully booted in 0.059046s"
Jun 28 21:28:10 qemu-ubuntu-containerd systemd[1]: Started containerd container runtime.
```

The article then discusses CNI configuration for `cri-docker`.
We aren't using `cri-docker`.
And it appears that our `containerd` uses some kind of CNI config by default.
- `containerd` default configuration location is `/etc/containerd/config.toml`
    - I am not sure if this is for CNI?
    - There is no file here on my machine, so it is not written
      - I assume when started it chooses sane defaults


Is anything still running?

```bash
# nerdctl can look for kubernetes containers
# I assume that this is specified since our kubelet is
# responsible for creating these containers via the
# watching of the directory ~/k8s/kubelet-static-pod/
sudo nerdctl --namespace k8s.io ps -a
# check the logs of a container, for fun
sudo nerdctl --namespace=k8s.io logs 74106d346cbe
```
